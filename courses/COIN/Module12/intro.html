<!DOCTYPE html>
<HTML lang="en">
  <HEAD>
    <META HTTP-EQUIV="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="../../all.min.css">
    <link rel="stylesheet" href="../../styles.min.css">
    <link rel="stylesheet" href="../../custom.css">
    <link rel="stylesheet" href="../../style-2022.css">
    <title>Introduction / Module 12 / CCCS 660</TITLE>

  </head>
  <body class="content" role="document">
    <section class="bg-">
      <div class="container-fluid">      
	<h1>Introduction</h1>
	<p>
	  When an AI model produces an output, it is reasonable to
	  want to know <em>why</em> that output was given. Tracing
	  back the origin of the output in terms of the insides of the
	  model and the data present in the input is the process of
	  explaining the workings of the model. This is the focus of
	  explainable AI (XAI). It is much easier to do when the model
	  has been built with explainability in mind, although
	  traditional black-box models are not completely hopeless
	  either.
	</p>
	<h2 class="topic-heading">Learning outcomes</h2>
	<p>
	  This module will help you do the following:
	  <ul class="action-items">
	    <li>Quantify the impact of input features in the output of an AI model</li>
	    <li>Visualize the relative effects of input features in the output of an AI model</li>
	    <li>Assess the limitations of existing XAI approaches</li>
	  </ul>
	</p>
	<h2 class="topic-heading">Warm-up</h2>
	<p>
	  E-books on explainable AI (pick at least one and browse it
	  for a bit):
	  <ul class="action-items">
	    <li><a target="_blank"
	    href="https://mcgill.on.worldcat.org/oclc/1348479214">Munn
	    et al., 2022</a></li>
	    <li><a target="_blank"
	    href="https://mcgill.on.worldcat.org/oclc/1350079336">Mehta
	    et al/. 2023</a></li>
	    <li><a target="_blank"
	    href="https://mcgill.on.worldcat.org/oclc/1289339048">Kamath
	    and Lui, 2021</a></li>
	  </ul>
	</p>
	<h3>Warm-up assessment</h3>
	<p>
	  After having browsed the ebook(s), make a list of at least a
	  half a dozen of possible real-world applications of AI
	  (whether contemporary or speculations of future use). For
	  each application, rate now crucial it is for the AI to be an
	  XAI and what exactly needs to be explained in each
	  setting. Again, please treat this as a thought exercise for
	  yourself instead of something to look up online or prompt at
	  LLM about.
	</p>
	<h2 class="topic-heading">Concepts</h2>
	<p>
	  After this module, you should be familiar with the following concepts:
	  <ul class="action-items">
	    <li>Explainability</li>
	    <li>Trust</li>
	    <li>XAI</li>
	  </ul>
	</p>	
	<p>
	  Remember that you can always look concepts up in the
	  <a target="_blank"
	     href="https://scs-technology-and-innovation.github.io/courses/TI.html">glossary</a>.
	  Should anything be missing or insufficient,
	  please <a target="_blank"
		    href="https://forms.office.com/r/VZpfFrZhRu">report</a> it.
	</p>
    </section>
    <footer>
      <p>
	Copyright Â©
	<script>
	  document.write(new Date().getFullYear());
	</script>
	McGill University
      </p>
    </footer>
    <script src="../../jquery-3.3.1.slim.min.js"></script>
    <script src="../../popper.min.js"></script>
    <script src="../../bootstrap.min.js"></script>
    <script src="../../scripts.min.js "></script>
  </body>
</html>
